---
phase: 02-author-mode-backend
plan: 03
type: execute
wave: 3
depends_on:
  - 02-02
files_modified:
  - bond/graph/nodes/structure.py
  - bond/graph/nodes/checkpoint_1.py
  - bond/graph/nodes/writer.py
  - bond/graph/graph.py
autonomous: true
requirements:
  - AUTH-03
  - AUTH-04
  - AUTH-05
  - AUTH-06
  - AUTH-08
  - AUTH-11

must_haves:
  truths:
    - "structure_node generates a heading outline (H1/H2/H3 in Markdown) from research_report using RESEARCH_MODEL; on rejection, the node re-runs using cp1_feedback (edited structure + note) as additional context"
    - "checkpoint_1_node pauses the graph via interrupt() exposing research_report, heading_structure, and cp1_iterations; user can approve or supply an edited structure and optional note"
    - "writer_node produces a Markdown draft with: primary keyword in H1 and first paragraph, correct heading hierarchy (# H1, ## H2, ### H3), a Meta Description line of 150-160 characters, minimum MIN_WORD_COUNT words, and 3-5 RAG exemplar style fragments injected as few-shot prefix in the system prompt"
    - "If SEO constraints are not met, writer_node silently auto-retries up to 2 times before setting draft_validated=False and surfacing the failure to the caller"
    - "On Checkpoint 2 rejection (Plan 04), writer_node uses cp2_feedback for targeted section revision while preserving unchanged sections"
  artifacts:
    - path: "bond/graph/nodes/structure.py"
      provides: "structure_node function: generates H1/H2/H3 Markdown outline from research_report; incorporates cp1_feedback on re-runs"
      exports: ["structure_node"]
    - path: "bond/graph/nodes/checkpoint_1.py"
      provides: "checkpoint_1_node function: single interrupt() call exposing research_report + heading_structure; processes approve/reject response"
      exports: ["checkpoint_1_node"]
    - path: "bond/graph/nodes/writer.py"
      provides: "writer_node function: SEO-compliant draft generation with RAG few-shot injection and constraint validation with 2-retry loop"
      exports: ["writer_node", "_validate_draft", "_build_writer_prompt"]
  key_links:
    - from: "bond/graph/nodes/writer.py"
      to: "bond/store/chroma.py"
      via: "get_corpus_collection().query() for RAG exemplar fragments"
      pattern: "get_corpus_collection|get_or_create_corpus_collection"
    - from: "bond/graph/nodes/checkpoint_1.py"
      to: "langgraph.types.interrupt"
      via: "single interrupt() call with research_report and heading_structure"
      pattern: "interrupt\\("
    - from: "bond/graph/nodes/writer.py"
      to: "bond/config.settings"
      via: "settings.draft_model, settings.min_word_count"
      pattern: "settings\\.draft_model|settings\\.min_word_count"
---

<objective>
Implement the structure node, Checkpoint 1 HITL node, and writer node. After this plan, the graph can execute the full path from START through research → structure proposal → human approval → draft generation with RAG style injection. Only Checkpoint 2 and metadata save remain (Plan 04).

Purpose: The writer node is the most complex in the pipeline — it combines SEO constraint enforcement, RAG exemplar injection, and targeted section revision. Getting it right here avoids refactoring when Checkpoint 2 is wired in Plan 04.
Output: Three working nodes. structure_node generates an H1/H2/H3 outline. checkpoint_1_node pauses for human approval. writer_node produces a validated, RAG-stylized SEO draft.
</objective>

<execution_context>
@/Users/franciszekmarzynski/.claude/get-shit-done/workflows/execute-plan.md
@/Users/franciszekmarzynski/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-author-mode-backend/02-CONTEXT.md
@.planning/phases/02-author-mode-backend/02-RESEARCH.md
@.planning/phases/02-author-mode-backend/02-01-SUMMARY.md
@.planning/phases/02-author-mode-backend/02-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Structure node and Checkpoint 1 HITL node (AUTH-03, AUTH-04)</name>
  <files>
    bond/graph/nodes/structure.py
    bond/graph/nodes/checkpoint_1.py
    bond/graph/graph.py
  </files>
  <action>
**1. bond/graph/nodes/structure.py**

The structure node generates an H1/H2/H3 heading outline from the research report. On re-runs (when cp1_approved=False from a previous iteration), it incorporates cp1_feedback (user-edited structure + optional note) as additional context for regeneration.

Key rules:
- Uses RESEARCH_MODEL (settings.research_model) — same as researcher_node (AUTH-11)
- On re-run: if cp1_feedback is set, include it in the prompt as "Poprzednia struktura nagłówków edytowana przez użytkownika" context
- Output format: pure Markdown heading outline, no body paragraphs (example below)
- heading_structure replaces any previous value in state

```python
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from bond.config import settings
from bond.graph.state import AuthorState


def _get_research_llm():
    """Return LLM for research/analysis tasks based on RESEARCH_MODEL env var."""
    model = settings.research_model
    if "claude" in model.lower():
        return ChatAnthropic(model=model, max_tokens=800)
    return ChatOpenAI(model=model, max_tokens=800)


def structure_node(state: AuthorState) -> dict:
    """
    Generate H1/H2/H3 heading structure from research_report.
    On regeneration, incorporates cp1_feedback (user-edited outline + note).
    """
    llm = _get_research_llm()
    topic = state["topic"]
    keywords = state.get("keywords", [])
    primary_keyword = keywords[0] if keywords else topic
    research_report = state.get("research_report", "")
    cp1_feedback = state.get("cp1_feedback")
    cp1_iterations = state.get("cp1_iterations", 0)

    if cp1_feedback and cp1_iterations > 0:
        # Re-run with user feedback: treat edited structure as strong prior
        prompt = f"""Jesteś redaktorem SEO. Zaproponuj poprawioną strukturę nagłówków (H1/H2/H3) artykułu.

TEMAT: {topic}
SŁOWA KLUCZOWE: {', '.join(keywords)}
GŁÓWNE SŁOWO KLUCZOWE (musi być w H1): {primary_keyword}

Użytkownik edytował poprzednią strukturę i dodał uwagi:
---
{cp1_feedback}
---

Na podstawie tych uwag i raportu badawczego, zaproponuj ostateczną strukturę nagłówków.
Uwzględnij sugestie użytkownika możliwie dokładnie.

RAPORT BADAWCZY:
{research_report[:2000]}

Zwróć TYLKO strukturę nagłówków w formacie Markdown (# H1, ## H2, ### H3). Bez treści artykułu."""
    else:
        # First run
        prompt = f"""Jesteś redaktorem SEO. Na podstawie raportu badawczego zaproponuj strukturę nagłówków artykułu.

TEMAT: {topic}
SŁOWA KLUCZOWE: {', '.join(keywords)}
GŁÓWNE SŁOWO KLUCZOWE (musi być w H1): {primary_keyword}

WYMAGANIA:
- H1 musi zawierać główne słowo kluczowe
- Struktura: 1x H1, 3-6x H2, opcjonalnie H3 pod H2
- Nagłówki po polsku, SEO-friendly, konkretne

RAPORT BADAWCZY:
{research_report[:2000]}

Zwróć TYLKO strukturę nagłówków w formacie Markdown (# H1, ## H2, ### H3). Bez treści artykułu."""

    heading_structure = llm.invoke(prompt).content.strip()
    return {"heading_structure": heading_structure}
```

**2. bond/graph/nodes/checkpoint_1.py**

CRITICAL: This node contains ONLY the interrupt() call. No LLM calls, no Exa calls — only the pause that surfaces data to the caller and processes the resume value.

Per locked user decision:
- On rejection: user provides an edited H1/H2/H3 structure directly (as Markdown text) + optional free-text note
- Both are concatenated into cp1_feedback which is passed to structure_node on re-run

```python
from langgraph.types import interrupt

from bond.graph.state import AuthorState


def checkpoint_1_node(state: AuthorState) -> dict:
    """
    Checkpoint 1: pause for human review of research report and heading structure.

    Surfaces: research_report, heading_structure, cp1_iterations.
    Resume format:
      Approve: {"approved": True}
      Reject:  {"approved": False, "edited_structure": "# ...", "note": "Optional note"}

    On rejection: edited_structure + note are concatenated into cp1_feedback.
    structure_node reads cp1_feedback on its next run.
    """
    user_response = interrupt({
        "checkpoint": "checkpoint_1",
        "research_report": state.get("research_report", ""),
        "heading_structure": state.get("heading_structure", ""),
        "cp1_iterations": state.get("cp1_iterations", 0),
        "instructions": (
            "Zatwierdź lub odrzuć raport i strukturę nagłówków. "
            "Przy odrzuceniu: edytuj strukturę nagłówków bezpośrednio i dodaj opcjonalną notatkę."
        ),
    })

    if user_response.get("approved"):
        return {"cp1_approved": True}

    # Rejection: concatenate edited structure + note into cp1_feedback
    edited_structure = user_response.get("edited_structure", state.get("heading_structure", ""))
    note = user_response.get("note", "")
    feedback = edited_structure
    if note:
        feedback = f"{edited_structure}\n\nUwaga: {note}"

    return {
        "cp1_approved": False,
        "cp1_feedback": feedback,
        "cp1_iterations": state.get("cp1_iterations", 0) + 1,
    }
```

**3. bond/graph/graph.py — register both nodes**

Replace stubs for structure and checkpoint_1:

```python
# Add to imports in graph.py:
from bond.graph.nodes.structure import structure_node as _structure_node
from bond.graph.nodes.checkpoint_1 import checkpoint_1_node as _checkpoint_1_node

# Update _node_registry:
_node_registry["structure"] = _structure_node
_node_registry["checkpoint_1"] = _checkpoint_1_node
```
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

python -c "
from bond.graph.nodes.structure import structure_node
from bond.graph.nodes.checkpoint_1 import checkpoint_1_node
print('structure_node importable:', callable(structure_node))
print('checkpoint_1_node importable:', callable(checkpoint_1_node))
"

python -c "
from bond.graph.graph import compile_graph
graph = compile_graph()
print('Graph compiles with 4 real nodes (duplicate_check, researcher, structure, checkpoint_1)')
"
```
Both complete without error.
  </verify>
  <done>structure_node and checkpoint_1_node import without error. compile_graph() succeeds. The graph's _node_registry no longer has stub functions for these four nodes.</done>
</task>

<task type="auto">
  <name>Task 2: Writer node with RAG injection and SEO constraint validation (AUTH-05, AUTH-06, AUTH-08, AUTH-11)</name>
  <files>
    bond/graph/nodes/writer.py
    bond/graph/graph.py
  </files>
  <action>
**bond/graph/nodes/writer.py**

This is the most complex node in the pipeline. It combines:
1. RAG few-shot injection — fetches 3-5 exemplar style fragments from Phase 1 corpus (AUTH-06)
2. SEO-compliant draft generation using DRAFT_MODEL (AUTH-05, AUTH-11)
3. Silent auto-retry (max 2) if hard constraints fail (per user decision)
4. Targeted section revision using cp2_feedback on re-runs (AUTH-08)

Key rules:
- RAG fragments: query Phase 1 `bond_style_corpus_v1` collection; prefer `source_type="own"` (own text); fall back to all types if own-text count < 3
- Few-shot injection: inject as system prompt prefix (soft prompt injection per research recommendation — most natural style transfer)
- SEO hard constraints (all must pass for draft_validated=True):
  - Primary keyword in H1 line
  - Primary keyword in first non-heading paragraph
  - Meta description: exactly one line matching `Meta-description:` or `Meta opis:` pattern, 150-160 chars
  - Word count >= MIN_WORD_COUNT (default 800)
- Auto-retry: if _validate_draft returns any False, regenerate silently (up to 2 more attempts)
- On Checkpoint 2 rejection (cp2_feedback set): targeted revision — prompt instructs LLM to revise ONLY the flagged sections and preserve all others

```python
import re
from typing import Optional

from bond.config import settings
from bond.graph.state import AuthorState
from bond.store.chroma import get_corpus_collection


# ---------------------------------------------------------------------------
# RAG exemplar retrieval
# ---------------------------------------------------------------------------

def _fetch_rag_exemplars(topic: str, n: int = 5) -> list[str]:
    """
    Fetch style exemplar fragments from Phase 1 corpus.
    Prefers own_text source; falls back to all types if < 3 own-text results found.
    Returns a list of text strings.
    """
    collection = get_corpus_collection()
    if collection is None or collection.count() == 0:
        return []

    # Try own_text first
    try:
        own_results = collection.query(
            query_texts=[topic],
            n_results=n,
            where={"source_type": "own"},
            include=["documents"],
        )
        own_docs = own_results["documents"][0] if own_results["documents"] else []
    except Exception:
        own_docs = []

    if len(own_docs) >= 3:
        return own_docs[:n]

    # Fall back to all source types
    try:
        all_results = collection.query(
            query_texts=[topic],
            n_results=n,
            include=["documents"],
        )
        return all_results["documents"][0] if all_results["documents"] else []
    except Exception:
        return []


# ---------------------------------------------------------------------------
# SEO constraint validation
# ---------------------------------------------------------------------------

def _validate_draft(draft: str, primary_keyword: str, min_words: int) -> dict[str, bool]:
    """Check all hard SEO constraints. Returns dict of constraint_name -> passed."""
    lines = draft.split("\n")
    h1_lines = [l for l in lines if re.match(r"^#\s+", l)]
    # First non-empty, non-heading paragraph
    first_para = next(
        (l.strip() for l in lines if l.strip() and not l.strip().startswith("#")),
        ""
    )

    # Meta description: accept "Meta-description:", "Meta opis:", "Meta description:" patterns
    meta_match = re.search(
        r"(?:Meta[- ]?[Dd]escription|Meta opis)[:\s]+(.+)",
        draft,
        re.IGNORECASE,
    )
    meta_desc = meta_match.group(1).strip() if meta_match else ""

    word_count = len(draft.split())
    pk_lower = primary_keyword.lower()

    return {
        "keyword_in_h1": bool(h1_lines and pk_lower in h1_lines[0].lower()),
        "keyword_in_first_para": pk_lower in first_para.lower(),
        "meta_desc_length_ok": 150 <= len(meta_desc) <= 160,
        "word_count_ok": word_count >= min_words,
    }


# ---------------------------------------------------------------------------
# Prompt builder
# ---------------------------------------------------------------------------

def _build_writer_prompt(
    topic: str,
    keywords: list[str],
    heading_structure: str,
    research_report: str,
    exemplars: list[str],
    min_words: int,
    cp2_feedback: Optional[str] = None,
    current_draft: Optional[str] = None,
) -> str:
    """Build the system+user prompt for the writer LLM."""
    primary_keyword = keywords[0] if keywords else topic
    other_keywords = ", ".join(keywords[1:]) if len(keywords) > 1 else "brak"

    exemplar_section = ""
    if exemplars:
        formatted = "\n\n---\n\n".join(exemplars[:5])
        exemplar_section = f"""## WZORCE STYLISTYCZNE (Few-Shot)
Poniższe fragmenty ilustrują pożądany styl pisania. Pisz w podobnym tonie i stylu — nie kopiuj treści, tylko styl.

{formatted}

---
"""

    if cp2_feedback and current_draft:
        # Targeted revision mode: preserve unchanged sections
        return f"""Jesteś redaktorem. Użytkownik odrzucił draft artykułu i wskazał sekcje do poprawki.

{exemplar_section}## ZADANIE
Popraw TYLKO wskazane sekcje. Zachowaj pozostałe sekcje bez zmian.

## FEEDBACK UŻYTKOWNIKA
{cp2_feedback}

## OBECNY DRAFT (do poprawki)
{current_draft}

## WYMAGANIA SEO (muszą być spełnione po poprawce)
- Główne słowo kluczowe "{primary_keyword}" w H1 i pierwszym akapicie
- Meta-description: dokładnie jedna linia zaczynająca się od "Meta-description:" zawierająca 150-160 znaków
- Minimum {min_words} słów
- Hierarchia nagłówków: # H1 → ## H2 → ### H3

Zwróć CAŁY artykuł (poprawione sekcje + niezmienione sekcje)."""
    else:
        # Fresh draft generation
        return f"""Jesteś ekspertem SEO copywriterem piszącym po polsku.

{exemplar_section}## TEMAT
{topic}

## SŁOWA KLUCZOWE
Główne: {primary_keyword}
Poboczne: {other_keywords}

## STRUKTURA NAGŁÓWKÓW (obowiązkowa)
{heading_structure}

## RAPORT BADAWCZY (informacje do uwzględnienia)
{research_report[:3000]}

## WYMAGANIA SEO (wszystkie obowiązkowe)
1. Główne słowo kluczowe "{primary_keyword}" musi być w H1 i w pierwszym akapicie
2. Poprawna hierarchia nagłówków: # H1, ## H2, ### H3
3. Meta-description: JEDNA linia w formacie "Meta-description: [treść]" zawierająca dokładnie 150-160 znaków
4. Minimum {min_words} słów (nie licząc nagłówków i meta-description)
5. Naturalne wplecenie słów kluczowych (bez keyword stuffing)

Napisz kompletny artykuł blogowy w Markdown."""


# ---------------------------------------------------------------------------
# Writer node
# ---------------------------------------------------------------------------

def writer_node(state: AuthorState) -> dict:
    """
    Generate SEO-compliant draft with RAG style injection.
    Auto-retries up to 2 times if hard constraints fail.
    On cp2_feedback: targeted section revision (preserves unchanged sections).
    """
    from langchain_anthropic import ChatAnthropic
    from langchain_openai import ChatOpenAI

    topic = state["topic"]
    keywords = state.get("keywords", [])
    primary_keyword = keywords[0] if keywords else topic
    heading_structure = state.get("heading_structure", "")
    research_report = state.get("research_report", "")
    cp2_feedback = state.get("cp2_feedback")
    current_draft = state.get("draft")  # for targeted revision
    min_words = settings.min_word_count

    # Select DRAFT_MODEL LLM (AUTH-11)
    draft_model = settings.draft_model
    if "claude" in draft_model.lower():
        llm = ChatAnthropic(model=draft_model, max_tokens=4096, temperature=0.7)
    else:
        llm = ChatOpenAI(model=draft_model, max_tokens=4096, temperature=0.7)

    # Fetch RAG exemplars from Phase 1 corpus
    exemplars = _fetch_rag_exemplars(topic, n=5)

    # Generate draft with silent auto-retry (max 2 additional attempts = 3 total)
    draft = ""
    validation = {}
    max_attempts = 3
    for attempt in range(max_attempts):
        prompt = _build_writer_prompt(
            topic=topic,
            keywords=keywords,
            heading_structure=heading_structure,
            research_report=research_report,
            exemplars=exemplars,
            min_words=min_words,
            cp2_feedback=cp2_feedback if attempt == 0 else None,  # feedback only on first targeted attempt
            current_draft=current_draft if attempt == 0 else None,
        )
        draft = llm.invoke(prompt).content.strip()
        validation = _validate_draft(draft, primary_keyword, min_words)

        all_passed = all(validation.values())
        if all_passed:
            return {"draft": draft, "draft_validated": True}

        if attempt < max_attempts - 1:
            # Silent retry — log which constraints failed
            failed = [k for k, v in validation.items() if not v]
            print(f"Writer auto-retry {attempt + 1}/{max_attempts - 1}: failed constraints: {failed}")

    # All retries exhausted — surface failure (user will see draft_validated=False)
    failed_constraints = [k for k, v in validation.items() if not v]
    print(f"WARNING: Draft failed validation after {max_attempts} attempts. Failed: {failed_constraints}")
    return {"draft": draft, "draft_validated": False}
```

**bond/graph/graph.py — register writer_node**

```python
# Add to imports in graph.py:
from bond.graph.nodes.writer import writer_node as _writer_node

# Update _node_registry:
_node_registry["writer"] = _writer_node
```
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Verify imports
python -c "
from bond.graph.nodes.writer import writer_node, _validate_draft, _fetch_rag_exemplars
print('writer_node importable:', callable(writer_node))
"

# Verify SEO validation logic
python -c "
from bond.graph.nodes.writer import _validate_draft

# Test with a minimal valid draft
valid_draft = '''# Content marketing dla B2B SaaS — kompletny przewodnik

Content marketing dla B2B SaaS to kluczowa strategia pozyskiwania klientów.

## Dlaczego content marketing jest ważny

Treści edukacyjne budują zaufanie i generują ruch organiczny.

## Jak zacząć content marketing

Zacznij od audytu obecnego contentu i wyznaczenia celów.

### Analiza odbiorców

Poznaj swoją grupę docelową zanim zaczniesz pisać.

## Mierzenie wyników content marketingu

Śledź metryki: organiczny ruch, konwersje, czas na stronie.

Meta-description: Content marketing dla B2B SaaS pozwala budować zaufanie i pozyskiwać klientów organicznie. Poznaj sprawdzone strategie.
''' + ' lorem ipsum' * 100

result = _validate_draft(valid_draft, 'content marketing dla B2B SaaS', 800)
print('Validation result:', result)
assert result['keyword_in_h1'] == True, 'keyword_in_h1 failed'
assert result['keyword_in_first_para'] == True, 'keyword_in_first_para failed'
print('SEO validation logic ok')
"

# Verify graph compiles with all implemented nodes
python -c "
from bond.graph.graph import compile_graph
graph = compile_graph()
print('Graph with 5 real nodes compiles ok:', sorted(graph.nodes.keys()))
"
```
  </verify>
  <done>writer_node, _validate_draft, _fetch_rag_exemplars all import without error. _validate_draft correctly detects keyword_in_h1, keyword_in_first_para. compile_graph() succeeds with writer_node registered (not a stub).</done>
</task>

</tasks>

<verification>
After both tasks complete:
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Full node import verification
python -c "
from bond.graph.nodes.structure import structure_node
from bond.graph.nodes.checkpoint_1 import checkpoint_1_node
from bond.graph.nodes.writer import writer_node
from bond.graph.graph import compile_graph
graph = compile_graph()
expected_real = {'duplicate_check', 'researcher', 'structure', 'checkpoint_1', 'writer'}
print('5 nodes implemented:', expected_real)
print('2 stubs remain:', {'checkpoint_2', 'save_metadata'})
print('Graph compiles ok.')
"

# Verify meta-description validation handles length correctly
python -c "
from bond.graph.nodes.writer import _validate_draft
# 155-char meta description (valid)
meta_155 = 'Content marketing dla B2B SaaS to strategia pozyskiwania klientów przez treści edukacyjne. Poznaj sprawdzone techniki.'
assert len(meta_155) == 118  # check the string length for reference
draft = '# Test content marketing dla B2B SaaS\n\nContent marketing dla B2B SaaS jest ważny.\n\nMeta-description: ' + meta_155 + '.\n' + 'słowo ' * 900
result = _validate_draft(draft, 'content marketing dla B2B SaaS', 800)
print('Meta-desc length validation ok. word_count_ok:', result['word_count_ok'])
"
```
</verification>

<success_criteria>
- structure_node imports and is registered in graph (not a stub)
- checkpoint_1_node imports; contains exactly one interrupt() call; processes both approve and reject paths correctly
- writer_node imports and is registered; _fetch_rag_exemplars returns list (empty if corpus not populated — no crash)
- _validate_draft correctly identifies keyword_in_h1, keyword_in_first_para, meta_desc_length_ok, word_count_ok
- compile_graph() succeeds with 5 real nodes and 2 stubs (checkpoint_2, save_metadata)
</success_criteria>

<output>
After completion, create `.planning/phases/02-author-mode-backend/02-03-SUMMARY.md` documenting:
- Structure node regeneration approach (cp1_feedback incorporation)
- Writer node RAG injection strategy (soft prompt prefix, own-text preference)
- SEO validation logic and auto-retry pattern
- Any deviations from planned approach or pitfalls encountered
</output>
