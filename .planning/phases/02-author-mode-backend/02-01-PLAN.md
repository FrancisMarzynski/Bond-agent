---
phase: 02-author-mode-backend
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - .env.example
  - bond/graph/__init__.py
  - bond/graph/state.py
  - bond/graph/graph.py
  - bond/graph/nodes/__init__.py
  - bond/db/__init__.py
  - bond/db/metadata_log.py
  - bond/db/schema.sql
autonomous: true
requirements:
  - AUTH-01
  - AUTH-11
  - DUPL-04

must_haves:
  truths:
    - "AuthorState TypedDict is importable and contains all required fields: topic, keywords, thread_id, search_cache, cp1_iterations, cp2_iterations, metadata_saved, and all optional fields"
    - "The compiled graph is importable via `from bond.graph import compile_graph` and compiles without error against SqliteSaver"
    - "Metadata Log schema is created in SQLite on first call and CRUD functions work (create table, insert row, query by embedding)"
    - "All Phase 2 env vars are present in .env.example: EXA_API_KEY, RESEARCH_MODEL, DRAFT_MODEL, MIN_WORD_COUNT, DUPLICATE_THRESHOLD, CHECKPOINT_DB_PATH, METADATA_DB_PATH"
  artifacts:
    - path: "bond/graph/state.py"
      provides: "AuthorState TypedDict with all pipeline fields"
      exports: ["AuthorState"]
    - path: "bond/graph/graph.py"
      provides: "build_author_graph() and compile_graph() with SqliteSaver; all 7 nodes wired with conditional edges"
      exports: ["build_author_graph", "compile_graph"]
    - path: "bond/db/metadata_log.py"
      provides: "create_metadata_tables(), save_article_metadata(), get_article_by_id() functions; separate SQLite file from LangGraph checkpoint DB"
      exports: ["create_metadata_tables", "save_article_metadata"]
  key_links:
    - from: "bond/graph/graph.py"
      to: "bond/graph/state.py"
      via: "StateGraph(AuthorState)"
      pattern: "StateGraph\\(AuthorState\\)"
    - from: "bond/graph/graph.py"
      to: "langgraph.checkpoint.sqlite"
      via: "SqliteSaver compile"
      pattern: "SqliteSaver"
    - from: "bond/db/metadata_log.py"
      to: "bond_metadata.db"
      via: "sqlite3.connect METADATA_DB_PATH"
      pattern: "sqlite3\\.connect.*METADATA_DB_PATH|metadata_db_path"
---

<objective>
Bootstrap the Phase 2 graph infrastructure: define AuthorState, wire all 7 graph nodes (with stub implementations), compile the graph with SqliteSaver, and create the Metadata Log database module. This is the foundation every subsequent Phase 2 plan builds on.

Purpose: Plans 02-04 all import from bond/graph/state.py and bond/graph/graph.py. Getting the state schema and graph wiring right here prevents refactoring debt downstream. The Metadata Log is also needed by the duplicate check node (Plan 02) and save_metadata node (Plan 04).
Output: Importable compiled LangGraph StateGraph with SqliteSaver checkpointer; AuthorState with all required fields; Metadata Log SQLite module.
</objective>

<execution_context>
@/Users/franciszekmarzynski/.claude/get-shit-done/workflows/execute-plan.md
@/Users/franciszekmarzynski/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-author-mode-backend/02-CONTEXT.md
@.planning/phases/02-author-mode-backend/02-RESEARCH.md
@.planning/phases/01-rag-corpus-onboarding/01-01-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Phase 2 dependencies, env vars, and AuthorState TypedDict</name>
  <files>
    pyproject.toml
    .env.example
    bond/graph/__init__.py
    bond/graph/state.py
    bond/graph/nodes/__init__.py
  </files>
  <action>
**1. pyproject.toml — add Phase 2 dependencies**

Add the following to the existing `dependencies` list in pyproject.toml (do NOT replace existing Phase 1 dependencies — append to the list):

```
"langgraph>=0.2",
"langgraph-checkpoint-sqlite>=3.0.3",
"exa-py>=2.4.0",
"langchain-openai>=0.2",
"langchain-anthropic>=0.2",
```

Run `uv sync` after updating.

**2. .env.example — add Phase 2 variables**

Append to the existing .env.example (preserve all Phase 1 variables):

```
# Phase 2: Author Mode Backend
EXA_API_KEY=your-exa-api-key-here
RESEARCH_MODEL=claude-3-5-haiku-20241022
DRAFT_MODEL=claude-3-5-sonnet-20241022
MIN_WORD_COUNT=800
DUPLICATE_THRESHOLD=0.85
CHECKPOINT_DB_PATH=./data/bond_checkpoints.db
METADATA_DB_PATH=./data/bond_metadata.db
```

**3. bond/graph/state.py — AuthorState TypedDict**

```python
from typing import Optional, TypedDict


class AuthorState(TypedDict):
    # --- Input ---
    topic: str
    keywords: list[str]
    thread_id: str

    # --- Duplicate detection ---
    duplicate_match: Optional[dict]     # {"title": str, "date": str, "similarity": float} or None
    duplicate_override: Optional[bool]  # True = proceed; False = abort; None = no match

    # --- Research ---
    # search_cache keys are topic strings; values are list[dict] with title/url/summary
    # Full text is stripped after report generation to avoid state bloat (Pitfall 4)
    search_cache: dict
    research_report: Optional[str]      # formatted Markdown report

    # --- Structure ---
    heading_structure: Optional[str]    # H1/H2/H3 outline as Markdown

    # --- Checkpoint 1 ---
    cp1_approved: Optional[bool]
    cp1_feedback: Optional[str]         # edited structure + optional note from user
    cp1_iterations: int                 # counts regeneration loops

    # --- Draft ---
    draft: Optional[str]                # full Markdown draft
    draft_validated: Optional[bool]     # True = passed all SEO constraint checks

    # --- Checkpoint 2 ---
    cp2_approved: Optional[bool]
    cp2_feedback: Optional[str]         # section-targeted feedback from user
    cp2_iterations: int                 # counts regeneration loops (soft cap at 3)

    # --- Output ---
    metadata_saved: bool
```

**4. bond/graph/nodes/__init__.py and bond/graph/__init__.py**

Both are empty (just a comment `# bond graph package`). The nodes/ subpackage will be populated in Plans 02-04.
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent
uv sync
python -c "from bond.graph.state import AuthorState; s = AuthorState(topic='test', keywords=['kw'], thread_id='t1', search_cache={}, cp1_iterations=0, cp2_iterations=0, metadata_saved=False, duplicate_match=None, duplicate_override=None, research_report=None, heading_structure=None, cp1_approved=None, cp1_feedback=None, draft=None, draft_validated=None, cp2_approved=None, cp2_feedback=None); print('AuthorState ok:', s['topic'])"
```
Command prints "AuthorState ok: test" with no errors.
  </verify>
  <done>uv sync completes without errors. `from bond.graph.state import AuthorState` imports successfully and all fields are accessible without KeyError.</done>
</task>

<task type="auto">
  <name>Task 2: Graph wiring with stub nodes, SqliteSaver, and Metadata Log</name>
  <files>
    bond/graph/graph.py
    bond/db/__init__.py
    bond/db/metadata_log.py
    bond/db/schema.sql
  </files>
  <action>
**1. bond/db/schema.sql — Metadata Log schema**

```sql
-- Separate from LangGraph checkpoint DB (bond_checkpoints.db)
-- Stores published article metadata for duplicate detection and history

CREATE TABLE IF NOT EXISTS metadata_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    thread_id TEXT NOT NULL,
    topic TEXT NOT NULL,
    published_date TEXT NOT NULL,   -- ISO 8601 UTC
    mode TEXT NOT NULL DEFAULT 'author',
    created_at TEXT NOT NULL
);

-- Indexes for common query patterns
CREATE INDEX IF NOT EXISTS idx_metadata_log_published_date ON metadata_log (published_date);
```

**2. bond/db/metadata_log.py — SQLite CRUD for Metadata Log**

This module manages a separate SQLite file (METADATA_DB_PATH) distinct from bond_checkpoints.db. The ChromaDB `metadata_log` collection (for embedding-based duplicate search) is managed separately in bond/store/chroma.py — this module only handles the relational record.

```python
import os
import sqlite3
from datetime import datetime, timezone
from bond.config import settings


def _get_conn() -> sqlite3.Connection:
    os.makedirs(os.path.dirname(os.path.abspath(settings.metadata_db_path)), exist_ok=True)
    conn = sqlite3.connect(settings.metadata_db_path, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    # Create tables on first connection
    schema_path = os.path.join(os.path.dirname(__file__), "schema.sql")
    with open(schema_path) as f:
        conn.executescript(f.read())
    conn.commit()
    return conn


def save_article_metadata(thread_id: str, topic: str, mode: str = "author") -> int:
    """Insert a metadata record. Returns the new row id."""
    conn = _get_conn()
    now = datetime.now(timezone.utc).isoformat()
    cursor = conn.execute(
        "INSERT INTO metadata_log (thread_id, topic, published_date, mode, created_at) VALUES (?, ?, ?, ?, ?)",
        (thread_id, topic, now, mode, now),
    )
    conn.commit()
    row_id = cursor.lastrowid
    conn.close()
    return row_id


def get_recent_articles(limit: int = 50) -> list[dict]:
    """Return most recent metadata_log entries as dicts."""
    conn = _get_conn()
    rows = conn.execute(
        "SELECT * FROM metadata_log ORDER BY published_date DESC LIMIT ?",
        (limit,),
    ).fetchall()
    conn.close()
    return [dict(r) for r in rows]
```

Also update `bond/config.py` to add the two new Phase 2 settings fields by appending to the existing Settings class:

```python
# Add to the Settings class in bond/config.py:
checkpoint_db_path: str = "./data/bond_checkpoints.db"
metadata_db_path: str = "./data/bond_metadata.db"
exa_api_key: str = ""
research_model: str = "claude-3-5-haiku-20241022"
draft_model: str = "claude-3-5-sonnet-20241022"
min_word_count: int = 800
duplicate_threshold: float = 0.85
```

**3. bond/graph/graph.py — StateGraph with stub nodes and SqliteSaver**

The graph is wired with all 7 nodes and correct conditional edges. Node implementations are stubs (raise NotImplementedError) — they will be replaced in Plans 02-04. The graph structure and routing logic are finalized here so Plans 02-04 only replace stub bodies.

```python
import sqlite3
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.sqlite import SqliteSaver

from bond.graph.state import AuthorState
from bond.config import settings


# ---------------------------------------------------------------------------
# Stub node implementations — replaced in Plans 02-04
# ---------------------------------------------------------------------------

def _duplicate_check_node(state: AuthorState) -> dict:
    raise NotImplementedError("duplicate_check_node not yet implemented (Plan 02)")


def _researcher_node(state: AuthorState) -> dict:
    raise NotImplementedError("researcher_node not yet implemented (Plan 02)")


def _structure_node(state: AuthorState) -> dict:
    raise NotImplementedError("structure_node not yet implemented (Plan 03)")


def _checkpoint_1_node(state: AuthorState) -> dict:
    raise NotImplementedError("checkpoint_1_node not yet implemented (Plan 03)")


def _writer_node(state: AuthorState) -> dict:
    raise NotImplementedError("writer_node not yet implemented (Plan 03)")


def _checkpoint_2_node(state: AuthorState) -> dict:
    raise NotImplementedError("checkpoint_2_node not yet implemented (Plan 04)")


def _save_metadata_node(state: AuthorState) -> dict:
    raise NotImplementedError("save_metadata_node not yet implemented (Plan 04)")


# ---------------------------------------------------------------------------
# Dynamic node loader — Plans 02-04 register real implementations
# ---------------------------------------------------------------------------

_node_registry: dict = {
    "duplicate_check": _duplicate_check_node,
    "researcher": _researcher_node,
    "structure": _structure_node,
    "checkpoint_1": _checkpoint_1_node,
    "writer": _writer_node,
    "checkpoint_2": _checkpoint_2_node,
    "save_metadata": _save_metadata_node,
}


def register_node(name: str, fn) -> None:
    """Called by each nodes/*.py module to replace its stub."""
    _node_registry[name] = fn


# ---------------------------------------------------------------------------
# Routing functions (routing logic is stable — do not change in later plans)
# ---------------------------------------------------------------------------

def _route_after_duplicate_check(state: AuthorState) -> str:
    """Route to researcher unless user explicitly aborted the duplicate warning."""
    if state.get("duplicate_override") is False:
        return END
    return "researcher"


def _route_after_cp1(state: AuthorState) -> str:
    """Loop back to structure node on rejection; advance to writer on approval."""
    if state.get("cp1_approved"):
        return "writer"
    return "structure"


def _route_after_cp2(state: AuthorState) -> str:
    """Loop back to writer on rejection (soft cap enforced inside checkpoint_2 node);
    advance to save_metadata on approval."""
    if state.get("cp2_approved"):
        return "save_metadata"
    return "writer"


# ---------------------------------------------------------------------------
# Graph builder
# ---------------------------------------------------------------------------

def build_author_graph() -> StateGraph:
    builder = StateGraph(AuthorState)

    # Register nodes (uses current registry — stubs until Plans 02-04 run)
    for name, fn in _node_registry.items():
        builder.add_node(name, fn)

    # Edges
    builder.add_edge(START, "duplicate_check")
    builder.add_conditional_edges(
        "duplicate_check",
        _route_after_duplicate_check,
        {"researcher": "researcher", END: END},
    )
    builder.add_edge("researcher", "structure")
    builder.add_edge("structure", "checkpoint_1")
    builder.add_conditional_edges(
        "checkpoint_1",
        _route_after_cp1,
        {"writer": "writer", "structure": "structure"},
    )
    builder.add_edge("writer", "checkpoint_2")
    builder.add_conditional_edges(
        "checkpoint_2",
        _route_after_cp2,
        {"save_metadata": "save_metadata", "writer": "writer"},
    )
    builder.add_edge("save_metadata", END)

    return builder


def compile_graph():
    """Compile the graph with SqliteSaver. check_same_thread=False is required."""
    import os
    os.makedirs(os.path.dirname(os.path.abspath(settings.checkpoint_db_path)), exist_ok=True)
    builder = build_author_graph()
    checkpointer = SqliteSaver(
        sqlite3.connect(settings.checkpoint_db_path, check_same_thread=False)
    )
    return builder.compile(checkpointer=checkpointer)
```

**4. bond/db/__init__.py** — empty (`# bond db package`).
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent
python -c "
from bond.graph.graph import compile_graph
graph = compile_graph()
print('Graph compiled ok. Nodes:', list(graph.nodes.keys()))
"

python -c "
from bond.db.metadata_log import save_article_metadata, get_recent_articles
row_id = save_article_metadata('test-thread-001', 'Testowy temat artykułu')
rows = get_recent_articles(limit=5)
assert len(rows) >= 1, 'No rows returned'
assert rows[0]['topic'] == 'Testowy temat artykułu', rows[0]
print('Metadata Log ok: row_id', row_id)
"
```
Both commands print confirmation without errors.
  </verify>
  <done>compile_graph() returns a compiled graph with 7 nodes in .nodes. save_article_metadata() inserts a row and get_recent_articles() returns it. data/bond_checkpoints.db and data/bond_metadata.db files are created in the data/ directory.</done>
</task>

</tasks>

<verification>
After both tasks complete:
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Verify graph structure and SqliteSaver wiring
python -c "
from bond.graph.graph import compile_graph
from bond.graph.state import AuthorState
graph = compile_graph()
expected_nodes = {'duplicate_check', 'researcher', 'structure', 'checkpoint_1', 'writer', 'checkpoint_2', 'save_metadata'}
actual_nodes = set(graph.nodes.keys())
assert expected_nodes.issubset(actual_nodes), f'Missing nodes: {expected_nodes - actual_nodes}'
print('All 7 nodes present:', sorted(actual_nodes))
"

# Verify env var settings loaded correctly
python -c "
from bond.config import settings
assert hasattr(settings, 'checkpoint_db_path'), 'missing checkpoint_db_path'
assert hasattr(settings, 'metadata_db_path'), 'missing metadata_db_path'
assert hasattr(settings, 'duplicate_threshold'), 'missing duplicate_threshold'
assert settings.duplicate_threshold == 0.85, settings.duplicate_threshold
print('Config ok. Threshold:', settings.duplicate_threshold)
"

# Verify SQLite schema was created
python -c "
import sqlite3
from bond.config import settings
conn = sqlite3.connect(settings.metadata_db_path)
tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()
table_names = [t[0] for t in tables]
assert 'metadata_log' in table_names, f'metadata_log table missing: {table_names}'
print('Schema ok. Tables:', table_names)
"
```
</verification>

<success_criteria>
- uv sync adds langgraph, langgraph-checkpoint-sqlite, exa-py, langchain-openai, langchain-anthropic without error
- AuthorState TypedDict imports successfully and all fields are accessible
- compile_graph() returns a compiled graph with all 7 nodes present
- data/bond_checkpoints.db is created by compile_graph()
- data/bond_metadata.db with metadata_log table is created by first metadata_log function call
- bond/config.py Settings includes checkpoint_db_path, metadata_db_path, duplicate_threshold, min_word_count, research_model, draft_model fields
</success_criteria>

<output>
After completion, create `.planning/phases/02-author-mode-backend/02-01-SUMMARY.md` documenting:
- Files created and their purpose
- Graph wiring structure and routing logic
- Key decisions: stub-based node replacement pattern, separate SQLite files for checkpoints vs metadata
- Any deviations from planned approach
</output>
