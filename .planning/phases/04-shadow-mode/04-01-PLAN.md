---
phase: 04-shadow-mode
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - bond/graph/state.py
  - bond/graph/graph.py
  - bond/graph/nodes/shadow_analyze.py
  - bond/graph/nodes/shadow_annotate.py
  - bond/graph/nodes/__init__.py
autonomous: true
requirements:
  - SHAD-01
  - SHAD-02
  - SHAD-03
  - SHAD-04

must_haves:
  truths:
    - "BondState TypedDict is importable and contains all AuthorState fields plus all shadow fields: shadow_input_text, shadow_corpus_fragments, shadow_annotations, shadow_corrected_text, shadow_rejected_ids, shadow_rejection_reason, shadow_iterations, shadow_cp_approved, shadow_previous_annotations, and mode"
    - "AuthorState alias is preserved in bond/graph/state.py so existing Phase 2 node imports do not break"
    - "build_bond_graph() replaces the former add_edge(START, 'duplicate_check') with add_conditional_edges(START, route_by_mode, ...) routing on state['mode']"
    - "shadow_analyze_node retrieves up to 5 corpus fragments via two-pass ChromaDB query (own text preferred) and returns them as shadow_corpus_fragments"
    - "shadow_annotate_node calls the DRAFT_MODEL LLM via with_structured_output(AnnotationResult) and returns shadow_annotations (list of Annotation dicts), shadow_corrected_text (string with all non-rejected annotations applied), and shadow_previous_annotations (snapshot of prior round for status tracking)"
    - "AnnotationResult Pydantic model has annotations: list[Annotation] and alignment_summary: str; Annotation has annotation_id, original_span, replacement, reason fields"
  artifacts:
    - path: "bond/graph/state.py"
      provides: "BondState TypedDict with author + shadow fields; AuthorState = BondState alias"
      exports: ["BondState", "AuthorState"]
    - path: "bond/graph/graph.py"
      provides: "build_bond_graph() with dual-branch routing; compile_graph() unchanged API"
      exports: ["build_bond_graph", "compile_graph"]
    - path: "bond/graph/nodes/shadow_analyze.py"
      provides: "shadow_analyze_node — ChromaDB two-pass retrieval"
      exports: ["shadow_analyze_node"]
    - path: "bond/graph/nodes/shadow_annotate.py"
      provides: "shadow_annotate_node, AnnotationResult, Annotation — LLM structured output + text assembly"
      exports: ["shadow_annotate_node", "AnnotationResult", "Annotation"]
  key_links:
    - from: "bond/graph/graph.py"
      to: "bond/graph/state.py"
      via: "StateGraph(BondState)"
      pattern: "StateGraph\\(BondState\\)"
    - from: "bond/graph/graph.py"
      to: "route_by_mode"
      via: "add_conditional_edges(START, route_by_mode, ...)"
      pattern: "add_conditional_edges.*START.*route_by_mode"
    - from: "bond/graph/nodes/shadow_annotate.py"
      to: "DRAFT_MODEL env var"
      via: "ChatOpenAI(model=os.environ['DRAFT_MODEL'])"
      pattern: "DRAFT_MODEL"
    - from: "bond/graph/nodes/shadow_analyze.py"
      to: "bond_style_corpus_v1"
      via: "chromadb.PersistentClient + get_collection"
      pattern: "bond_style_corpus_v1"
---

<objective>
Extend the LangGraph graph to support Shadow mode routing and implement the two core Shadow backend nodes: corpus analysis and annotation generation.

Purpose: All Shadow mode behavior depends on a working graph routing branch and structured annotation output. This plan creates those foundations before the HITL checkpoint and frontend are added in Plan 02.
Output: Extended BondState with shadow fields; dual-branch graph routing; shadow_analyze_node and shadow_annotate_node implementations.
</objective>

<execution_context>
@/Users/franciszekmarzynski/.claude/get-shit-done/workflows/execute-plan.md
@/Users/franciszekmarzynski/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-shadow-mode/04-CONTEXT.md
@.planning/phases/04-shadow-mode/04-RESEARCH.md
@.planning/phases/02-author-mode-backend/02-01-PLAN.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rename AuthorState to BondState, add Shadow fields, rewire graph START routing</name>
  <files>
    bond/graph/state.py
    bond/graph/graph.py
    bond/graph/nodes/__init__.py
  </files>
  <action>
**1. bond/graph/state.py — rename to BondState, add shadow fields, keep alias**

Replace the existing `AuthorState` TypedDict with `BondState`. Add backward-compat alias `AuthorState = BondState` AFTER the class definition so all existing Phase 2 node imports continue working without modification.

Full updated state.py:

```python
from typing import Literal, Optional, TypedDict


class BondState(TypedDict):
    # --- Routing ---
    mode: Literal["author", "shadow"]   # determines routing branch

    # --- Author mode input ---
    topic: Optional[str]
    keywords: Optional[list[str]]
    thread_id: str

    # --- Duplicate detection ---
    duplicate_match: Optional[dict]     # {"title": str, "date": str, "similarity": float} or None
    duplicate_override: Optional[bool]  # True = proceed; False = abort; None = no match

    # --- Research ---
    search_cache: dict
    research_report: Optional[str]

    # --- Structure ---
    heading_structure: Optional[str]

    # --- Checkpoint 1 ---
    cp1_approved: Optional[bool]
    cp1_feedback: Optional[str]
    cp1_iterations: int

    # --- Draft ---
    draft: Optional[str]
    draft_validated: Optional[bool]

    # --- Checkpoint 2 ---
    cp2_approved: Optional[bool]
    cp2_feedback: Optional[str]
    cp2_iterations: int

    # --- Output ---
    metadata_saved: bool

    # --- Shadow mode fields ---
    shadow_input_text: Optional[str]               # SHAD-01: submitted text
    shadow_corpus_fragments: Optional[list[dict]]  # SHAD-02: retrieved style examples
    shadow_annotations: Optional[list[dict]]       # SHAD-03: list of Annotation dicts
    shadow_corrected_text: Optional[str]           # SHAD-04: full corrected version
    shadow_rejected_ids: Optional[list[str]]       # IDs rejected in current round
    shadow_rejection_reason: Optional[str]         # free-text feedback
    shadow_iterations: int                         # iteration counter (soft cap at 3)
    shadow_cp_approved: Optional[bool]
    shadow_previous_annotations: Optional[list[dict]]  # prior round for status highlighting


# Backward-compat alias — Phase 2 nodes import AuthorState; keep until all migrated
AuthorState = BondState
```

**2. bond/graph/graph.py — replace START edge with dual-branch conditional routing**

Read the existing graph.py (built in Phase 2 Plan 01). Make two changes:

a) Import BondState instead of AuthorState (keep AuthorState import as alias if other parts use it):
```python
from bond.graph.state import BondState
```

b) Add `route_by_mode` function BEFORE `build_author_graph`:
```python
from typing import Literal

def route_by_mode(state: "BondState") -> Literal["duplicate_check", "shadow_analyze"]:
    """Route to Author or Shadow branch based on 'mode' field."""
    if state.get("mode") == "shadow":
        return "shadow_analyze"
    return "duplicate_check"
```

c) In `build_author_graph` (rename function to `build_bond_graph` — keep `build_author_graph` as alias):
- Replace `builder.add_edge(START, "duplicate_check")` with:
```python
builder.add_conditional_edges(
    START,
    route_by_mode,
    {"duplicate_check": "duplicate_check", "shadow_analyze": "shadow_analyze"},
)
```
- Add shadow stub nodes to the registry so the graph compiles (shadow_analyze, shadow_annotate, shadow_checkpoint):
```python
def _shadow_analyze_stub(state): raise NotImplementedError("shadow_analyze (Plan 04-01)")
def _shadow_annotate_stub(state): raise NotImplementedError("shadow_annotate (Plan 04-01)")
def _shadow_checkpoint_stub(state): raise NotImplementedError("shadow_checkpoint (Plan 04-02)")

builder.add_node("shadow_analyze", _shadow_analyze_stub)
builder.add_node("shadow_annotate", _shadow_annotate_stub)
builder.add_node("shadow_checkpoint", _shadow_checkpoint_stub)
```
- Add stub shadow edges so the builder doesn't error on unconnected nodes:
```python
builder.add_edge("shadow_analyze", "shadow_annotate")
builder.add_edge("shadow_annotate", "shadow_checkpoint")
builder.add_edge("shadow_checkpoint", END)
```

d) After `build_author_graph`, add alias: `build_bond_graph = build_author_graph`

e) In `compile_graph()`: update `StateGraph(AuthorState)` → `StateGraph(BondState)` (or it will use the alias which is equivalent — both reference the same class).

**3. bond/graph/nodes/__init__.py** — add a comment noting Shadow nodes will be imported here once implemented: `# Shadow nodes imported by Plan 04-01 and 04-02`
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Verify BondState importable with all fields
python -c "
from bond.graph.state import BondState, AuthorState
assert BondState is AuthorState, 'alias broken'
s = BondState(
    mode='author', topic='test', keywords=['kw'], thread_id='t1',
    search_cache={}, cp1_iterations=0, cp2_iterations=0,
    metadata_saved=False, shadow_iterations=0,
    duplicate_match=None, duplicate_override=None, research_report=None,
    heading_structure=None, cp1_approved=None, cp1_feedback=None,
    draft=None, draft_validated=None, cp2_approved=None, cp2_feedback=None,
    shadow_input_text=None, shadow_corpus_fragments=None, shadow_annotations=None,
    shadow_corrected_text=None, shadow_rejected_ids=None, shadow_rejection_reason=None,
    shadow_cp_approved=None, shadow_previous_annotations=None,
)
print('BondState ok, mode field:', s['mode'])
"

# Verify graph compiles with dual-branch routing
python -c "
from bond.graph.graph import compile_graph
graph = compile_graph()
nodes = set(graph.nodes.keys())
required = {'duplicate_check', 'researcher', 'shadow_analyze', 'shadow_annotate', 'shadow_checkpoint'}
assert required.issubset(nodes), f'Missing nodes: {required - nodes}'
print('Graph ok. Nodes:', sorted(nodes))
"
```
Both commands complete without errors. Graph has shadow_analyze, shadow_annotate, shadow_checkpoint nodes.
  </verify>
  <done>BondState importable with mode field + all shadow fields. AuthorState alias resolves to BondState. compile_graph() produces a graph that contains shadow_analyze, shadow_annotate, shadow_checkpoint nodes alongside all existing Author mode nodes. START is now routed via add_conditional_edges(START, route_by_mode, ...).</done>
</task>

<task type="auto">
  <name>Task 2: Implement shadow_analyze_node and shadow_annotate_node</name>
  <files>
    bond/graph/nodes/shadow_analyze.py
    bond/graph/nodes/shadow_annotate.py
    bond/graph/graph.py
  </files>
  <action>
**1. bond/graph/nodes/shadow_analyze.py — two-pass ChromaDB corpus retrieval**

This node embeds the submitted text using the same SentenceTransformer model as Phase 1/2 and retrieves up to 5 style corpus fragments (own text preferred, external as fill). Uses a module-level singleton to avoid re-loading the ~420MB model on every node call.

```python
"""Shadow analyze node — retrieve style corpus fragments for comparison."""
from __future__ import annotations

import chromadb
from sentence_transformers import SentenceTransformer

from bond.config import settings

# Module-level singleton — loaded once per process (same pattern as Phase 2 duplicate_check)
_embed_model: SentenceTransformer | None = None


def _get_embed_model() -> SentenceTransformer:
    global _embed_model
    if _embed_model is None:
        _embed_model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
    return _embed_model


def shadow_analyze_node(state: dict) -> dict:
    """Retrieve corpus style fragments relevant to the submitted text.

    Two-pass retrieval: prefer own texts (source_type='own'); fill remainder
    from external blogger entries if fewer than 5 own fragments available.

    Returns: shadow_corpus_fragments — list of dicts with 'text' and 'source_type' keys.
    """
    submitted = state["shadow_input_text"]
    if not submitted or not submitted.strip():
        return {"shadow_corpus_fragments": []}

    model = _get_embed_model()
    query_embedding = model.encode([submitted]).tolist()

    client = chromadb.PersistentClient(path=settings.chroma_path)
    try:
        corpus = client.get_collection("bond_style_corpus_v1")
    except Exception:
        # Corpus not yet populated — return empty fragments (caller should handle)
        return {"shadow_corpus_fragments": []}

    # Pass 1: own texts (SHAD-02: two-pass own-before-external weighting)
    own_result = corpus.query(
        query_embeddings=query_embedding,
        n_results=5,
        where={"source_type": "own"},
        include=["documents", "metadatas"],
    )
    own_docs = own_result["documents"][0] if own_result.get("documents") else []

    # Pass 2: external fill to reach 5 fragments total
    ext_docs: list[str] = []
    if len(own_docs) < 5:
        fill_n = 5 - len(own_docs)
        ext_result = corpus.query(
            query_embeddings=query_embedding,
            n_results=fill_n,
            where={"source_type": "external"},
            include=["documents", "metadatas"],
        )
        ext_docs = ext_result["documents"][0] if ext_result.get("documents") else []

    fragments = (
        [{"text": d, "source_type": "own"} for d in own_docs]
        + [{"text": d, "source_type": "external"} for d in ext_docs]
    )
    return {"shadow_corpus_fragments": fragments}
```

**2. bond/graph/nodes/shadow_annotate.py — LLM structured annotation output + text assembly**

This node is responsible for calling the LLM (DRAFT_MODEL) with structured output and assembling both the annotated text and the corrected text. It also tracks annotation status (new/modified/unchanged) for the UI highlighting requirement from CONTEXT.md.

```python
"""Shadow annotate node — generate structured annotations and corrected text."""
from __future__ import annotations

import os
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI


class Annotation(BaseModel):
    annotation_id: str = Field(
        description=(
            "Unique stable ID, e.g. 'ann_001'. Must be preserved across regeneration "
            "rounds for annotations that are NOT being regenerated."
        )
    )
    original_span: str = Field(
        description=(
            "Exact verbatim text from the submitted text to replace. Must be at least "
            "10 characters and unique enough in context to match unambiguously. "
            "Include surrounding sentence fragment if the phrase repeats in the text."
        )
    )
    replacement: str = Field(
        description="Corrected replacement text aligned with the author's style corpus."
    )
    reason: str = Field(
        description=(
            "Brief explanation referencing the author's style, e.g. "
            "'Your style uses shorter sentences here; this splits a compound clause.'"
        )
    )


class AnnotationResult(BaseModel):
    annotations: list[Annotation] = Field(
        description="All style corrections ordered by appearance in the text."
    )
    alignment_summary: str = Field(
        default="",
        description=(
            "Optional 1-2 sentence overall style alignment summary. "
            "Include ONLY if annotation count > 5; leave empty string otherwise."
        ),
    )


def _build_shadow_prompt(
    submitted_text: str,
    corpus_fragments: list[dict],
    rejected_ids: list[str],
    rejection_reason: str,
    previous_annotations: list[dict],
) -> str:
    exemplars = "\n\n---\n\n".join(f["text"] for f in corpus_fragments[:5])
    is_regeneration = bool(rejected_ids)
    prev_ann_str = ""
    if is_regeneration and previous_annotations:
        preserved = [
            a for a in previous_annotations
            if a["annotation_id"] not in rejected_ids
        ]
        preserved_summary = [
            {
                "annotation_id": a["annotation_id"],
                "original_span": a["original_span"],
                "replacement": a["replacement"],
            }
            for a in preserved
        ]
        prev_ann_str = f"""
Previously approved annotations — PRESERVE these annotation_id values and content EXACTLY:
{preserved_summary}

User rejected annotation IDs: {rejected_ids}
User feedback on rejected annotations: {rejection_reason or '(no reason given)'}

Generate NEW corrections ONLY for the rejected IDs. All other annotation_id values and their content must remain identical to the preserved list above.
"""

    return f"""You are a style editor. Annotate the submitted text with corrections that align it to the author's style corpus.

## Author Style Corpus Fragments
{exemplars}

## Submitted Text
{submitted_text}
{prev_ann_str}
## Instructions
- Analyze style (word choice, tone, rhythm), structure (paragraph flow, heading usage), grammar, and clarity against the corpus
- Annotate ALL deviations — comprehensive coverage, not just top-N
- Each annotation: provide exact original_span, replacement, brief reason referencing the author's style
- Make original_span unique enough to match unambiguously (minimum 10 characters; include surrounding context if the phrase repeats)
- Assign stable annotation_id values like 'ann_001', 'ann_002' in order of appearance in the text
- Return alignment_summary only if annotation count exceeds 5
"""


def _apply_annotations(original: str, annotations: list[Annotation]) -> str:
    """Apply all annotations via substring replacement to produce corrected text.

    Processes in reverse order of appearance to preserve correct offsets.
    Replaces only the first occurrence (count=1) — correct for unique original_spans.
    """
    corrected = original
    for ann in reversed(annotations):
        if ann.original_span in corrected:
            corrected = corrected.replace(ann.original_span, ann.replacement, 1)
    return corrected


def _mark_annotation_status(
    current: list[dict],
    previous: list[dict],
) -> list[dict]:
    """Add 'status': 'new' | 'modified' | 'unchanged' to each annotation.

    Used by the frontend to highlight which annotations changed after regeneration.
    """
    prev_map = {a["annotation_id"]: a for a in previous}
    result = []
    for ann in current:
        aid = ann["annotation_id"]
        if aid not in prev_map:
            result.append({**ann, "status": "new"})
        elif ann["replacement"] != prev_map[aid]["replacement"]:
            result.append({**ann, "status": "modified"})
        else:
            result.append({**ann, "status": "unchanged"})
    return result


def shadow_annotate_node(state: dict) -> dict:
    """Call DRAFT_MODEL LLM with structured output to produce annotations.

    Returns:
        shadow_annotations: list of Annotation dicts (with 'status' field on regeneration rounds)
        shadow_corrected_text: full text with all annotations applied
        shadow_previous_annotations: snapshot of current annotations (for next round comparison)
    """
    llm = ChatOpenAI(model=os.environ["DRAFT_MODEL"], temperature=0.3)
    structured_llm = llm.with_structured_output(AnnotationResult)

    prompt = _build_shadow_prompt(
        submitted_text=state["shadow_input_text"],
        corpus_fragments=state.get("shadow_corpus_fragments") or [],
        rejected_ids=state.get("shadow_rejected_ids") or [],
        rejection_reason=state.get("shadow_rejection_reason") or "",
        previous_annotations=state.get("shadow_previous_annotations") or [],
    )

    result: AnnotationResult = structured_llm.invoke(prompt)

    # Assemble corrected text by applying all annotations
    corrected = _apply_annotations(
        original=state["shadow_input_text"],
        annotations=result.annotations,
    )

    # Track annotation status for frontend highlighting (CONTEXT.md: "highlight which annotations are new or modified")
    previous = state.get("shadow_annotations") or []
    annotations_with_status = _mark_annotation_status(
        current=[a.model_dump() for a in result.annotations],
        previous=previous,
    )

    return {
        "shadow_annotations": annotations_with_status,
        "shadow_corrected_text": corrected,
        "shadow_previous_annotations": previous,  # snapshot before this round
    }
```

**3. bond/graph/graph.py — replace shadow stub nodes with real implementations**

After creating the node files above, update graph.py to import and use the real node functions instead of the stubs. In `build_author_graph` / `build_bond_graph`, replace:

```python
# Remove the three stub functions (_shadow_analyze_stub, _shadow_annotate_stub, _shadow_checkpoint_stub)
# and replace with real imports at the top of graph.py:

from bond.graph.nodes.shadow_analyze import shadow_analyze_node
from bond.graph.nodes.shadow_annotate import shadow_annotate_node

# shadow_checkpoint_stub remains until Plan 04-02 implements it
def _shadow_checkpoint_stub(state): raise NotImplementedError("shadow_checkpoint (Plan 04-02)")
```

Then change `builder.add_node("shadow_analyze", _shadow_analyze_stub)` → `builder.add_node("shadow_analyze", shadow_analyze_node)`
And `builder.add_node("shadow_annotate", _shadow_annotate_stub)` → `builder.add_node("shadow_annotate", shadow_annotate_node)`

The `_shadow_checkpoint_stub` stub remains for now (Plan 04-02 replaces it).
  </action>
  <verify>
```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Verify Pydantic models importable and schema is correct
python -c "
from bond.graph.nodes.shadow_annotate import Annotation, AnnotationResult, _apply_annotations, _mark_annotation_status

# Test _apply_annotations
anns = [
    Annotation(annotation_id='ann_001', original_span='krótkie zdanie testowe', replacement='zwięzłe zdanie testowe', reason='brevity'),
    Annotation(annotation_id='ann_002', original_span='bardzo długi i skomplikowany', replacement='złożony', reason='style'),
]
original = 'To jest krótkie zdanie testowe i bardzo długi i skomplikowany fragment tekstu.'
corrected = _apply_annotations(original, anns)
assert 'zwięzłe zdanie testowe' in corrected, f'ann_001 not applied: {corrected}'
assert 'złożony' in corrected, f'ann_002 not applied: {corrected}'
print('_apply_annotations ok:', corrected)

# Test _mark_annotation_status
current = [{'annotation_id': 'ann_001', 'replacement': 'new text'}, {'annotation_id': 'ann_002', 'replacement': 'same'}]
prev = [{'annotation_id': 'ann_001', 'replacement': 'old text'}, {'annotation_id': 'ann_002', 'replacement': 'same'}]
marked = _mark_annotation_status(current, prev)
statuses = {a['annotation_id']: a['status'] for a in marked}
assert statuses['ann_001'] == 'modified', statuses
assert statuses['ann_002'] == 'unchanged', statuses
print('_mark_annotation_status ok:', statuses)
"

# Verify graph imports shadow nodes without error
python -c "
from bond.graph.graph import compile_graph
graph = compile_graph()
nodes = set(graph.nodes.keys())
assert 'shadow_analyze' in nodes and 'shadow_annotate' in nodes
print('Graph with real shadow nodes ok. All nodes:', sorted(nodes))
"

# Verify shadow_analyze_node handles missing corpus gracefully
python -c "
from bond.graph.nodes.shadow_analyze import shadow_analyze_node
result = shadow_analyze_node({'shadow_input_text': 'test text', 'mode': 'shadow'})
print('shadow_analyze_node (empty corpus):', result)
assert 'shadow_corpus_fragments' in result
"
```
All three commands complete without errors.
  </verify>
  <done>shadow_analyze_node and shadow_annotate_node are implemented and importable. AnnotationResult / Annotation Pydantic models are defined with correct fields. _apply_annotations and _mark_annotation_status pass unit verification. graph.py uses real shadow_analyze and shadow_annotate implementations instead of stubs. shadow_checkpoint_stub remains as placeholder for Plan 04-02.</done>
</task>

</tasks>

<verification>
After both tasks complete:

```bash
cd /Users/franciszekmarzynski/Downloads/Bond-agent

# Full state + graph sanity check
python -c "
from bond.graph.state import BondState, AuthorState
from bond.graph.graph import compile_graph, build_bond_graph

# Alias must be same object
assert BondState is AuthorState, 'AuthorState alias broken'

# Shadow fields present
fields = BondState.__annotations__
required_shadow = {'mode', 'shadow_input_text', 'shadow_corpus_fragments',
                   'shadow_annotations', 'shadow_corrected_text', 'shadow_rejected_ids',
                   'shadow_rejection_reason', 'shadow_iterations', 'shadow_cp_approved',
                   'shadow_previous_annotations'}
missing = required_shadow - set(fields.keys())
assert not missing, f'Missing shadow fields: {missing}'
print('BondState fields ok:', sorted(required_shadow))

# Graph compiles with correct nodes
graph = compile_graph()
nodes = set(graph.nodes.keys())
required_nodes = {'duplicate_check', 'researcher', 'structure', 'checkpoint_1',
                  'writer', 'checkpoint_2', 'save_metadata',
                  'shadow_analyze', 'shadow_annotate', 'shadow_checkpoint'}
assert required_nodes.issubset(nodes), f'Missing: {required_nodes - nodes}'
print('All nodes present:', sorted(nodes))
"
```
</verification>

<success_criteria>
- BondState TypedDict has all 28+ fields including mode and all shadow_* fields
- AuthorState = BondState alias means all Phase 2 node imports continue to work
- compile_graph() produces a graph with both Author mode nodes and Shadow mode nodes (10 total)
- add_conditional_edges(START, route_by_mode, ...) replaces add_edge(START, "duplicate_check")
- shadow_analyze_node handles missing corpus without crashing (returns empty fragments list)
- shadow_annotate_node Pydantic models (Annotation, AnnotationResult) are importable with correct field definitions
- _apply_annotations applies corrections in reverse order using str.replace(..., 1) substring matching
- _mark_annotation_status correctly tags each annotation as new/modified/unchanged vs prior round
</success_criteria>

<output>
After completion, create `.planning/phases/04-shadow-mode/04-01-SUMMARY.md` documenting:
- BondState field inventory (new shadow fields added)
- Graph routing change: add_conditional_edges replacing add_edge at START
- AuthorState alias approach and backward-compat strategy
- shadow_analyze_node two-pass retrieval pattern
- shadow_annotate_node LLM call pattern, annotation assembly, status tracking
- Any deviations from planned approach
</output>
