---
phase: 01-rag-corpus-onboarding
plan: 03
type: execute
wave: 3
depends_on:
  - "01-01"
  - "01-02"
autonomous: false
requirements:
  - CORP-05
  - CORP-06
  - CORP-07
files_modified:
  - bond/corpus/smoke_test.py
  - bond/api/routes/corpus.py

must_haves:
  truths:
    - "GET /api/corpus/status returns article count, chunk count, and a low_corpus_warning string when article count is below LOW_CORPUS_THRESHOLD"
    - "GET /api/corpus/smoke-test returns top-N fragments with cosine similarity scores, source_type, article title, and text preview using two-pass own-then-external retrieval"
    - "source_type metadata is visible in every smoke test result — own text fragments are preferred when available"
    - "Low-corpus warning fires when article count < LOW_CORPUS_THRESHOLD (default 10) and is absent when count >= threshold"
  artifacts:
    - path: "bond/corpus/smoke_test.py"
      provides: "run_smoke_test(query, n_results) using two-pass retrieval (own-first, fill from external); returns ranked results with cosine similarity scores"
    - path: "bond/api/routes/corpus.py"
      provides: "GET /api/corpus/status and GET /api/corpus/smoke-test endpoints added to existing router"
  key_links:
    - from: "bond/api/routes/corpus.py GET /api/corpus/status"
      to: "bond/store/article_log.py"
      via: "get_article_count() and get_chunk_count()"
      pattern: "get_article_count|get_chunk_count"
    - from: "bond/api/routes/corpus.py GET /api/corpus/smoke-test"
      to: "bond/corpus/smoke_test.py"
      via: "run_smoke_test()"
      pattern: "run_smoke_test"
    - from: "bond/corpus/smoke_test.py"
      to: "bond/store/chroma.py"
      via: "get_corpus_collection().query() — two-pass own-then-external"
      pattern: "get_corpus_collection|source_type.*own|source_type.*external"
---

<objective>
Complete Phase 1 by adding corpus status visibility (CORP-06, CORP-07) and the retrieval smoke test (prerequisite for Phase 2). This plan also adds the final verification checkpoint so the developer can confirm retrieval quality before any LLM generation work begins.

Purpose: Without a working retrieval smoke test, Phase 2 has no quality gate. Without status visibility, the developer cannot tell if the corpus is adequately populated. These are the phase's exit criteria.
Output: GET /api/corpus/status and GET /api/corpus/smoke-test endpoints, plus a human verification checkpoint confirming retrieval quality on the real populated corpus.
</objective>

<execution_context>
@/Users/franciszekmarzynski/.claude/get-shit-done/workflows/execute-plan.md
@/Users/franciszekmarzynski/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-rag-corpus-onboarding/01-CONTEXT.md
@.planning/phases/01-rag-corpus-onboarding/01-RESEARCH.md
@.planning/phases/01-rag-corpus-onboarding/01-01-SUMMARY.md
@.planning/phases/01-rag-corpus-onboarding/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Retrieval smoke test module and corpus status + smoke-test endpoints</name>
  <files>
    bond/corpus/smoke_test.py
    bond/api/routes/corpus.py
  </files>
  <action>
**1. bond/corpus/smoke_test.py — Two-pass retrieval smoke test**

Implement per RESEARCH.md Pattern 8 and Pattern 9. Two-pass retrieval: own text first, fill remainder from external. Convert ChromaDB cosine distance to similarity score (score = 1 - distance).

```python
from bond.store.chroma import get_corpus_collection
from bond.config import settings

DEFAULT_QUERY = "styl pisania storytelling angażujące treści"


def run_smoke_test(
    query: str = DEFAULT_QUERY,
    n_results: int | None = None,
) -> list[dict]:
    """
    Query ChromaDB using two-pass retrieval (own text preferred, external fills remainder).
    Returns ranked results with cosine similarity scores and source metadata.

    Returns empty list with warning print if corpus is empty.
    """
    if n_results is None:
        n_results = settings.rag_top_k

    collection = get_corpus_collection()
    if collection.count() == 0:
        print("WARN: Corpus is empty — smoke test returned no results")
        return []

    # Pass 1: own text
    own_results = _query(collection, query, n_results, source_type="own")
    own_count = len(own_results)

    if own_count >= n_results:
        return own_results

    # Pass 2: fill remainder from external
    fill_count = n_results - own_count
    ext_results = _query(collection, query, fill_count, source_type="external")

    combined = own_results + ext_results
    # Re-rank combined by score descending (own results already preferred)
    combined.sort(key=lambda x: x["score"], reverse=True)
    return combined


def _query(collection, query: str, n: int, source_type: str) -> list[dict]:
    """Query ChromaDB filtered by source_type. Returns [] if no results."""
    try:
        results = collection.query(
            query_texts=[query],
            n_results=n,
            where={"source_type": source_type},
            include=["documents", "metadatas", "distances"],
        )
    except Exception as e:
        # ChromaDB raises if n_results > collection size for a filtered query
        # Retry with n_results=1 as minimum to check availability
        print(f"WARN: Retrieval for source_type={source_type} failed ({e}) — returning empty")
        return []

    docs = results.get("documents", [[]])[0]
    metas = results.get("metadatas", [[]])[0]
    distances = results.get("distances", [[]])[0]

    output = []
    for rank, (doc, meta, dist) in enumerate(zip(docs, metas, distances), start=1):
        output.append({
            "rank": rank,
            "score": round(1.0 - dist, 4),  # cosine distance → similarity
            "source_type": meta.get("source_type", "unknown"),
            "article_title": meta.get("article_title", "unknown"),
            "source_url": meta.get("source_url", ""),
            "fragment": doc[:300] + ("..." if len(doc) > 300 else ""),
        })
    return output
```

**2. Additions to bond/api/routes/corpus.py**

Add the following imports and endpoints after the existing endpoints. Do not modify existing routes.

Imports to add at the top of corpus.py (alongside existing imports):
```python
from bond.store.article_log import get_article_count, get_chunk_count
from bond.corpus.smoke_test import run_smoke_test
from bond.config import settings
```

New Pydantic models (add to corpus.py):
```python
class CorpusStatus(BaseModel):
    article_count: int
    chunk_count: int
    low_corpus_warning: str | None = None

class SmokeTestResult(BaseModel):
    query: str
    results: list[dict]
    result_count: int
```

New endpoints:
```python
@router.get("/status", response_model=CorpusStatus)
async def corpus_status_endpoint():
    """
    CORP-06: Return article count and chunk count.
    CORP-07: Include low_corpus_warning when article count < LOW_CORPUS_THRESHOLD.
    """
    article_count = get_article_count()
    chunk_count = get_chunk_count()

    warning = None
    if article_count < settings.low_corpus_threshold:
        warning = (
            f"Corpus contains only {article_count} article(s). "
            f"Recommend at least {settings.low_corpus_threshold} articles for reliable style retrieval."
        )

    return CorpusStatus(
        article_count=article_count,
        chunk_count=chunk_count,
        low_corpus_warning=warning,
    )


@router.get("/smoke-test", response_model=SmokeTestResult)
async def smoke_test_endpoint(
    query: str = DEFAULT_QUERY,
    n: int = 5,
):
    """
    Run retrieval smoke test against the corpus.
    Returns top-N fragments with cosine similarity scores and source metadata.
    """
    results = run_smoke_test(query=query, n_results=n)
    return SmokeTestResult(
        query=query,
        results=results,
        result_count=len(results),
    )
```

Add `DEFAULT_QUERY = "styl pisania storytelling angażujące treści"` as a module-level constant in corpus.py (reusing the value from smoke_test.py).
  </action>
  <verify>
```bash
uv run uvicorn bond.api.main:app --port 8001 &
sleep 5

# Status endpoint — empty corpus expected to show warning
curl -s http://localhost:8001/api/corpus/status | python3 -c "
import sys, json
d = json.load(sys.stdin)
print('Status:', d)
assert 'article_count' in d, d
assert 'chunk_count' in d, d
# Warning should be present when article_count < LOW_CORPUS_THRESHOLD (default 10)
if d['article_count'] < 10:
    assert d['low_corpus_warning'] is not None, 'Expected low_corpus_warning but got None'
    print('Low corpus warning present:', d['low_corpus_warning'])
print('status endpoint ok')
"

# Smoke test endpoint — empty corpus returns empty results list
curl -s "http://localhost:8001/api/corpus/smoke-test?n=3" | python3 -c "
import sys, json
d = json.load(sys.stdin)
print('Smoke test:', d)
assert 'results' in d, d
assert isinstance(d['results'], list), d
assert 'query' in d, d
print('smoke-test endpoint ok')
"

kill %1 2>/dev/null || true
```
  </verify>
  <done>GET /api/corpus/status returns {article_count, chunk_count, low_corpus_warning}. low_corpus_warning is populated when article_count &lt; 10 and null when above threshold. GET /api/corpus/smoke-test returns {query, results, result_count} — results is a list (empty if corpus empty, ranked results with score/source_type/article_title/fragment if populated).</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Checkpoint: Verify corpus status and retrieval quality on real data</name>
  <what-built>
All four ingestion paths (text paste, file upload, blog URL, Google Drive), corpus status endpoint with low-corpus warning, and retrieval smoke test endpoint with two-pass own-before-external retrieval. The complete Phase 1 RAG corpus pipeline is in place.

To reach this checkpoint, Claude will have:
1. Ingested at least 3 test articles via the text paste endpoint (POST /api/corpus/ingest/text)
2. Run GET /api/corpus/status to confirm article_count and chunk_count
3. Run GET /api/corpus/smoke-test to confirm retrieval returns results with scores and source metadata
  </what-built>
  <how-to-verify>
Start the server: `uv run uvicorn bond.api.main:app --reload`

**Step 1 — Ingest sample text (run this if corpus is empty):**
```bash
curl -X POST http://localhost:8000/api/corpus/ingest/text \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Copywriting to sztuka pisania tekstów, które angażują czytelnika od pierwszego słowa. Dobry copywriter wie, że storytelling jest kluczem do budowania relacji z odbiorcą. Każda historia musi mieć bohatera, konflikt i rozwiązanie. Emocje sprzedają, a fakty uzasadniają decyzję zakupową. Pisząc dla internetu, pamiętaj o nagłówkach H2 i H3, które ułatwiają skanowanie treści.",
    "title": "Podstawy copywritingu",
    "source_type": "own"
  }'
```

**Step 2 — Check corpus status:**
```
GET http://localhost:8000/api/corpus/status
```
Confirm: `article_count` >= 1, `chunk_count` >= 1.

**Step 3 — Run smoke test:**
```
GET http://localhost:8000/api/corpus/smoke-test?n=3
```
Confirm each result contains:
- `score` field between 0 and 1
- `source_type` of "own" or "external"
- `article_title` matching a previously ingested article
- `fragment` showing a meaningful text excerpt (not empty)

**Step 4 — Verify low-corpus warning:**
If `article_count` is below 10, `low_corpus_warning` in the status response should be non-null and describe the threshold.

**Step 5 — Optional: test file upload via curl:**
```bash
echo "Artykuł testowy do weryfikacji file upload. Treść artykułu jest wystarczająco długa aby system podzielił ją na fragmenty." > /tmp/test.txt
curl -X POST http://localhost:8000/api/corpus/ingest/file \
  -F "file=@/tmp/test.txt" \
  -F "source_type=external" \
  -F "title=Test File Article"
```
  </how-to-verify>
  <resume-signal>
Type "approved" if smoke test returns results with scores and source metadata, and status shows correct article/chunk counts.

If retrieval scores are unexpectedly low (all below 0.3) or source_type is missing from results, describe what you see and Claude will investigate.
  </resume-signal>
  <action>
No automated action — this is a human verification checkpoint. Claude will ingest 3 sample articles via text paste before presenting this checkpoint:

```bash
# Sample ingestion commands Claude runs before checkpoint
curl -X POST http://localhost:8000/api/corpus/ingest/text \
  -H "Content-Type: application/json" \
  -d '{"text": "Copywriting to sztuka pisania tekstów, które angażują czytelnika od pierwszego słowa. Dobry copywriter wie, że storytelling jest kluczem do budowania relacji z odbiorcą. Każda historia musi mieć bohatera, konflikt i rozwiązanie. Emocje sprzedają, a fakty uzasadniają decyzję zakupową.", "title": "Podstawy copywritingu", "source_type": "own"}'

curl -s http://localhost:8000/api/corpus/status
curl -s "http://localhost:8000/api/corpus/smoke-test?n=3"
```
  </action>
  <verify>
Human reviews smoke test output at http://localhost:8000/api/corpus/smoke-test — confirms results contain score, source_type, article_title, and fragment fields with meaningful content.
  </verify>
  <done>Human types "approved" confirming retrieval quality is acceptable for Phase 2 to begin.</done>
</task>

</tasks>

<verification>
Phase 1 is complete when all of the following are true:
1. `GET /api/corpus/status` returns correct article_count and chunk_count from SQLite (not ChromaDB chunk count used for article count)
2. `GET /api/corpus/status` includes low_corpus_warning when article_count < LOW_CORPUS_THRESHOLD
3. `GET /api/corpus/smoke-test` returns fragments with score (0-1 range), source_type ("own"/"external"), and article_title
4. Human checkpoint confirms retrieval quality is meaningful (scores > 0.3 for relevant queries)
5. All 4 ingestion endpoints registered and functional
6. No unhandled exceptions from any endpoint — all failures return warnings in response body
</verification>

<success_criteria>
- Corpus status endpoint correctly distinguishes article count from chunk count
- Low-corpus warning present below threshold, absent above threshold
- Smoke test two-pass retrieval returns own text first when available
- Human verification confirms retrieval quality before Phase 2 begins
- Complete OpenAPI docs at http://localhost:8000/docs show all 6 corpus endpoints
</success_criteria>

<output>
After completion and checkpoint approval, create `.planning/phases/01-rag-corpus-onboarding/01-03-SUMMARY.md` documenting:
- Smoke test retrieval quality observed during verification (typical scores, own vs external distribution)
- Low-corpus warning threshold behavior confirmed
- Any retrieval quality findings relevant to Phase 2 (e.g., optimal chunk size observed)
- Phase 1 complete: all 7 CORP requirements satisfied
</output>
